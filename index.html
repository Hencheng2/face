<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Replacement Tool</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);
            color: #fff;
            min-height: 100vh;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .container {
            max-width: 1200px;
            width: 100%;
        }
        
        header {
            text-align: center;
            padding: 20px 0;
            margin-bottom: 30px;
        }
        
        h1 {
            font-size: 2.8rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }
        
        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 600px;
            margin: 0 auto;
        }
        
        .main-content {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        .upload-section, .preview-section {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
            flex: 1;
            min-width: 350px;
        }
        
        .section-title {
            font-size: 1.5rem;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section-title svg {
            width: 24px;
            height: 24px;
        }
        
        .upload-area {
            border: 2px dashed rgba(255, 255, 255, 0.4);
            border-radius: 10px;
            padding: 30px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
            margin-bottom: 20px;
            position: relative;
            overflow: hidden;
        }
        
        .upload-area:hover {
            background: rgba(255, 255, 255, 0.1);
        }
        
        .upload-icon {
            font-size: 3rem;
            margin-bottom: 15px;
        }
        
        .file-input {
            display: none;
        }
        
        .btn {
            background: linear-gradient(90deg, #ff9966, #ff5e62);
            color: white;
            border: none;
            padding: 12px 25px;
            border-radius: 50px;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.3s;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            margin: 5px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }
        
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.25);
        }
        
        .btn:active {
            transform: translateY(0);
        }
        
        .btn:disabled {
            background: #555;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .btn-secondary {
            background: linear-gradient(90deg, #3a7bd5, #00d2ff);
        }
        
        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 20px;
            justify-content: center;
        }
        
        .video-container {
            position: relative;
            width: 100%;
            height: 300px;
            overflow: hidden;
            border-radius: 10px;
            background: #000;
            margin-bottom: 20px;
        }
        
        #video, #output {
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1); /* Mirror the video for a more natural feel */
        }
        
        #output {
            position: absolute;
            top: 0;
            left: 0;
        }
        
        .status {
            text-align: center;
            padding: 15px;
            margin-top: 15px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 8px;
            font-size: 0.9rem;
        }
        
        .instructions {
            margin-top: 30px;
            background: rgba(0, 0, 0, 0.2);
            padding: 20px;
            border-radius: 10px;
            max-width: 800px;
        }
        
        .instructions h3 {
            margin-bottom: 15px;
            text-align: center;
        }
        
        .instructions ol {
            padding-left: 20px;
            margin-bottom: 15px;
        }
        
        .instructions li {
            margin-bottom: 10px;
            line-height: 1.5;
        }
        
        .tips {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
        }
        
        footer {
            text-align: center;
            margin-top: 40px;
            opacity: 0.7;
            font-size: 0.9rem;
        }
        
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        @media (max-width: 768px) {
            .main-content {
                flex-direction: column;
            }
            
            h1 {
                font-size: 2.2rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Face Replacement Tool</h1>
            <p class="subtitle">Upload a photo and replace faces in your live video in real-time</p>
        </header>
        
        <div class="main-content">
            <div class="upload-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" />
                    </svg>
                    Upload Face Photo
                </h2>
                
                <div class="upload-area" id="uploadArea">
                    <div class="upload-icon">üìÅ</div>
                    <p>Click to browse or drag & drop a photo</p>
                    <p><small>(Max size: 5MB, Formats: JPG, PNG)</small></p>
                    <input type="file" id="photoUpload" class="file-input" accept="image/*">
                </div>
                
                <div class="preview" id="imagePreview"></div>
                
                <div class="controls">
                    <button id="startCamera" class="btn" disabled>
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M0 5a2 2 0 0 1 2-2h7.5a2 2 0 0 1 1.983 1.738l3.11-1.382A1 1 0 0 1 16 4.269v7.462a1 1 0 0 1-1.406.913l-3.111-1.382A2 2 0 0 1 9.5 13H2a2 2 0 0 1-2-2V5z"/>
                        </svg>
                        Start Camera
                    </button>
                    <button id="stopCamera" class="btn btn-secondary" disabled>
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M5.5 7.5A.5.5 0 0 1 6 7h4a.5.5 0 0 1 0 1H6a.5.5 0 0 1-.5-.5z"/>
                            <path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v8a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V4zm15 0a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V4z"/>
                        </svg>
                        Stop Camera
                    </button>
                </div>
                
                <div class="status" id="status">
                    Please upload a face photo to begin
                </div>
            </div>
            
            <div class="preview-section">
                <h2 class="section-title">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    Live Preview
                </h2>
                
                <div class="video-container">
                    <video id="video" autoplay playsinline></video>
                    <canvas id="output"></canvas>
                </div>
                
                <div class="controls">
                    <button id="takeSnapshot" class="btn" disabled>
                        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                            <path d="M10.5 8.5a2.5 2.5 0 1 1-5 0 2.5 2.5 0 0 1 5 0z"/>
                            <path d="M2 4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V6a2 2 0 0 0-2-2h-1.172a2 2 0 0 1-1.414-.586l-.828-.828A2 2 0 0 0 9.172 2H6.828a2 2 0 0 0-1.414.586l-.828.828A2 2 0 0 1 3.172 4H2zm.5 2a.5.5 0 1 1 0-1 .5.5 0 0 1 0 1zm9 2.5a3.5 3.5 0 1 1-7 0 3.5 3.5 0 0 1 7 0z"/>
                        </svg>
                        Take Snapshot
                    </button>
                </div>
                
                <div class="status">
                    Camera status: <span id="cameraStatus">Inactive</span>
                </div>
            </div>
        </div>
        
        <div class="instructions">
            <h3>How to use this tool:</h3>
            <ol>
                <li>Upload a clear frontal face photo using the upload area</li>
                <li>Click "Start Camera" and allow camera access when prompted</li>
                <li>Position your face in the camera view - the tool will automatically detect and replace it</li>
                <li>Use "Take Snapshot" to capture the result</li>
                <li>Click "Stop Camera" when finished</li>
            </ol>
            
            <div class="tips">
                <p><strong>Tips for best results:</strong></p>
                <ul>
                    <li>Use good lighting on your face</li>
                    <li>Look directly at the camera</li>
                    <li>Use a high-quality, clear photo for replacement</li>
                    <li>Avoid moving too quickly for better tracking</li>
                </ul>
            </div>
        </div>
        
        <footer>
            <p>Face Replacement Tool using TensorFlow.js FaceMesh | Created with HTML, CSS & JavaScript</p>
        </footer>
    </div>

    <!-- Load TensorFlow.js and FaceMesh model -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

    <script>
        // DOM elements
        const photoUpload = document.getElementById('photoUpload');
        const uploadArea = document.getElementById('uploadArea');
        const imagePreview = document.getElementById('imagePreview');
        const startCameraBtn = document.getElementById('startCamera');
        const stopCameraBtn = document.getElementById('stopCamera');
        const takeSnapshotBtn = document.getElementById('takeSnapshot');
        const statusText = document.getElementById('status');
        const cameraStatus = document.getElementById('cameraStatus');
        const video = document.getElementById('video');
        const outputCanvas = document.getElementById('output');
        const ctx = outputCanvas.getContext('2d');
        
        // Variables
        let faceImage = null;
        let stream = null;
        let isProcessing = false;
        let faceMesh = null;
        let model = null;
        
        // Event Listeners
        uploadArea.addEventListener('click', () => {
            photoUpload.click();
        });
        
        uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadArea.style.background = 'rgba(255, 255, 255, 0.2)';
        });
        
        uploadArea.addEventListener('dragleave', () => {
            uploadArea.style.background = '';
        });
        
        uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadArea.style.background = '';
            
            if (e.dataTransfer.files.length) {
                photoUpload.files = e.dataTransfer.files;
                handleImageUpload(e.dataTransfer.files[0]);
            }
        });
        
        photoUpload.addEventListener('change', (e) => {
            if (e.target.files.length) {
                handleImageUpload(e.target.files[0]);
            }
        });
        
        startCameraBtn.addEventListener('click', startCamera);
        stopCameraBtn.addEventListener('click', stopCamera);
        takeSnapshotBtn.addEventListener('click', takeSnapshot);
        
        // Initialize FaceMesh model
        async function setupFaceMesh() {
            statusText.innerHTML = '<span class="loading"></span> Loading face detection model...';
            
            // Set backend to WebGL for better performance
            await tf.setBackend('webgl');
            
            // Load FaceMesh model
            model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
            const detectorConfig = {
                runtime: 'tfjs',
                refineLandmarks: true,
                maxFaces: 1
            };
            
            try {
                faceMesh = await faceLandmarksDetection.createDetector(model, detectorConfig);
                statusText.textContent = 'Model loaded. Please upload a face photo.';
                return true;
            } catch (error) {
                console.error('Error loading FaceMesh model:', error);
                statusText.textContent = 'Error loading face detection model. Please refresh and try again.';
                return false;
            }
        }
        
        // Functions
        function handleImageUpload(file) {
            if (!file.type.match('image.*')) {
                statusText.textContent = 'Please upload an image file';
                return;
            }
            
            const reader = new FileReader();
            reader.onload = function(e) {
                faceImage = new Image();
                faceImage.onload = function() {
                    // Create thumbnail preview
                    imagePreview.innerHTML = `
                        <div style="text-align: center; margin-top: 15px;">
                            <p>Uploaded Image:</p>
                            <img src="${e.target.result}" style="max-width: 150px; max-height: 150px; border-radius: 8px; margin-top: 10px; border: 2px solid #fff;">
                        </div>
                    `;
                    
                    statusText.textContent = 'Face photo uploaded successfully!';
                    startCameraBtn.disabled = false;
                };
                faceImage.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }
        
        async function startCamera() {
            if (!faceMesh) {
                const modelLoaded = await setupFaceMesh();
                if (!modelLoaded) return;
            }
            
            try {
                statusText.textContent = 'Accessing camera...';
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 640, height: 480 }, 
                    audio: false 
                });
                
                video.srcObject = stream;
                startCameraBtn.disabled = true;
                stopCameraBtn.disabled = false;
                takeSnapshotBtn.disabled = false;
                
                video.addEventListener('loadedmetadata', function() {
                    outputCanvas.width = video.videoWidth;
                    outputCanvas.height = video.videoHeight;
                    statusText.textContent = 'Camera active. Detecting faces...';
                    cameraStatus.textContent = 'Active';
                    cameraStatus.style.color = '#7cff7c';
                    
                    // Start the face detection
                    detectFaces();
                });
            } catch (error) {
                statusText.textContent = 'Error accessing camera: ' + error.message;
                console.error('Camera error:', error);
            }
        }
        
        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            video.srcObject = null;
            startCameraBtn.disabled = false;
            stopCameraBtn.disabled = true;
            takeSnapshotBtn.disabled = true;
            isProcessing = false;
            
            // Clear canvas
            ctx.clearRect(0, 0, outputCanvas.width, outputCanvas.height);
            statusText.textContent = 'Camera stopped.';
            cameraStatus.textContent = 'Inactive';
            cameraStatus.style.color = '#fff';
        }
        
        function takeSnapshot() {
            if (!stream) return;
            
            // Create a temporary canvas to capture the current output
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = outputCanvas.width;
            tempCanvas.height = outputCanvas.height;
            
            // Draw the current output to the temporary canvas
            tempCtx.drawImage(outputCanvas, 0, 0);
            
            // Create a download link
            const dataURL = tempCanvas.toDataURL('image/png');
            const link = document.createElement('a');
            link.download = 'face-replacement.png';
            link.href = dataURL;
            link.click();
            
            statusText.textContent = 'Snapshot downloaded!';
            setTimeout(() => {
                if (stream) statusText.textContent = 'Camera active. Detecting faces...';
            }, 2000);
        }
        
        // Face detection and replacement function
        async function detectFaces() {
            if (!stream || isProcessing) return;
            
            isProcessing = true;
            
            const detect = async () => {
                if (!stream) {
                    isProcessing = false;
                    return;
                }
                
                // Draw the video frame
                ctx.save();
                ctx.scale(-1, 1);
                ctx.drawImage(video, -outputCanvas.width, 0, outputCanvas.width, outputCanvas.height);
                ctx.restore();
                
                if (faceImage && faceMesh) {
                    try {
                        // Estimate faces
                        const faces = await faceMesh.estimateFaces(video, { flipHorizontal: false });
                        
                        if (faces.length > 0) {
                            const face = faces[0];
                            
                            // Get the bounding box of the face
                            const box = face.box;
                            
                            // Draw the uploaded face image over the detected face
                            ctx.save();
                            ctx.scale(-1, 1);
                            
                            // Create a clipping path for the face
                            ctx.beginPath();
                            ctx.arc(
                                - (box.xMin + box.width/2), 
                                box.yMin + box.height/2, 
                                Math.min(box.width, box.height)/2, 
                                0, 
                                Math.PI * 2
                            );
                            ctx.closePath();
                            ctx.clip();
                            
                            // Draw the face image
                            ctx.drawImage(
                                faceImage, 
                                - (box.xMin + box.width/2 + box.width/2), 
                                box.yMin, 
                                box.width, 
                                box.height
                            );
                            
                            ctx.restore();
                            
                            // Draw a border around the replaced face
                            ctx.beginPath();
                            ctx.arc(
                                outputCanvas.width - (box.xMin + box.width/2),
                                box.yMin + box.height/2,
                                Math.min(box.width, box.height)/2,
                                0,
                                Math.PI * 2
                            );
                            ctx.strokeStyle = '#ff9966';
                            ctx.lineWidth = 2;
                            ctx.stroke();
                        }
                    } catch (error) {
                        console.error('Error detecting faces:', error);
                    }
                }
                
                // Continue detection
                requestAnimationFrame(detect);
            };
            
            // Start detection
            detect();
        }
        
        // Initialize the application
        window.addEventListener('load', () => {
            statusText.textContent = 'Initializing...';
            setTimeout(setupFaceMesh, 500);
        });
    </script>
</body>
</html>
